{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n",
      "\n",
      "WARNING: You are on Windows. If you detect any issue with pandarallel, be sure you checked out the Troubleshooting page:\n",
      "https://nalepae.github.io/pandarallel/troubleshooting/\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, learning_curve\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import plotly.graph_objects as go\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "data = []\n",
    "with open('clean_trips.json', 'r') as file:\n",
    "    for line in file:\n",
    "        data.append(json.loads(line))\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculate trip time in seconds\n",
    "df['trip_time'] = df['time']\n",
    "\n",
    "# Drop rows with missing values (if any)\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Prepare Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction functions\n",
    "def extract_features(row):\n",
    "    features = {}\n",
    "    features['mean_time_gap'] = np.mean(row['time_gap'])\n",
    "    features['std_time_gap'] = np.std(row['time_gap'])\n",
    "    features['min_time_gap'] = np.min(row['time_gap'])\n",
    "    features['max_time_gap'] = np.max(row['time_gap'])\n",
    "    \n",
    "    features['mean_lat'] = np.mean(row['lats'])\n",
    "    features['std_lat'] = np.std(row['lats'])\n",
    "    features['min_lat'] = np.min(row['lats'])\n",
    "    features['max_lat'] = np.max(row['lats'])\n",
    "    \n",
    "    features['mean_lng'] = np.mean(row['lngs'])\n",
    "    features['std_lng'] = np.std(row['lngs'])\n",
    "    features['min_lng'] = np.min(row['lngs'])\n",
    "    features['max_lng'] = np.max(row['lngs'])\n",
    "    \n",
    "    features['mean_dist_gap'] = np.mean(row['dist_gap'])\n",
    "    features['std_dist_gap'] = np.std(row['dist_gap'])\n",
    "    features['min_dist_gap'] = np.min(row['dist_gap'])\n",
    "    features['max_dist_gap'] = np.max(row['dist_gap'])\n",
    "    \n",
    "    return pd.Series(features)\n",
    "\n",
    "# Apply feature extraction to each row\n",
    "feature_df = df.apply(extract_features, axis=1)\n",
    "\n",
    "# Combine features with other relevant columns\n",
    "X = pd.concat([feature_df, df[['driverID', 'weekID', 'timeID', 'dateID']]], axis=1)\n",
    "y = df['trip_time']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 4: Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert non-numeric columns to numeric or drop them\n",
    "non_numeric_cols = X.select_dtypes(include=['object']).columns\n",
    "X[non_numeric_cols] = X[non_numeric_cols].apply(lambda col: pd.factorize(col)[0])\n",
    "\n",
    "# Ensure all features are numeric\n",
    "assert X.select_dtypes(include=['object']).empty, \"There are still non-numeric columns in X\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Hyperparameter Tuning and Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 3780 candidates, totalling 18900 fits\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': list(range(1, 202, 50)),\n",
    "    'max_depth': list(range(1, 8)),\n",
    "    'min_samples_leaf': list(range(1, 10)),\n",
    "    'max_leaf_nodes': [None] + list(range(10, 20, 2)),\n",
    "    'random_state': [42],\n",
    "    'criterion': ['squared_error', 'absolute_error']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestRegressor(), param_grid, cv=5, refit=True, verbose=1, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "model = RandomForestRegressor(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 6: Evaluate the Model with Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, valid_scores = learning_curve(\n",
    "    model, X_train, y_train, train_sizes=np.linspace(0.1, 1, 10), cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=train_sizes, y=-np.mean(train_scores, axis=1), name='Training error'))\n",
    "fig.add_trace(go.Scatter(x=train_sizes, y=-np.mean(valid_scores, axis=1), name='Validation error'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 7: Make Predictions and Calculate Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimations(test_data, model):\n",
    "    test_data['trip_time_estimate'] = model.predict(test_data.drop(columns=['trip_time']))\n",
    "    test_data['error'] = test_data['trip_time'] - test_data['trip_time_estimate']\n",
    "    test_data = test_data.query(\"error < 3600\")\n",
    "    return test_data\n",
    "\n",
    "plot_df = estimations(df.loc[X_test.index], model)\n",
    "\n",
    "# Plotting and metrics functions can be reused as is\n",
    "plot_graphs(plot_df)\n",
    "get_metrics(plot_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
